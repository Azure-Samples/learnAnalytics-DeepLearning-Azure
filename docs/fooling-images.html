<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Deep Learning on Azure</title>
  <meta name="description" content="Rendered version of Deep Learning on Azure materials.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Deep Learning on Azure" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Rendered version of Deep Learning on Azure materials." />
  <meta name="github-repo" content="Azure/learnAnalytics-DeepLearning-Azure" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Deep Learning on Azure" />
  
  <meta name="twitter:description" content="Rendered version of Deep Learning on Azure materials." />
  

<meta name="author" content="Ali Zaidi">


<meta name="date" content="2017-10-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="saliency-maps.html">
<link rel="next" href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Deep Learning on Azure</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#part-i---fundamentals-and-azure-for-machine-learning"><i class="fa fa-check"></i><b>1.1</b> Part I - Fundamentals and Azure for Machine Learning</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#part-ii---optimization"><i class="fa fa-check"></i><b>1.2</b> Part II - Optimization</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#part-iii---convolutional-neural-networks"><i class="fa fa-check"></i><b>1.3</b> Part III - Convolutional Neural Networks</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#part-iv---recurrent-networks"><i class="fa fa-check"></i><b>1.4</b> Part IV - Recurrent Networks</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#part-v---reinforcement-learning"><i class="fa fa-check"></i><b>1.5</b> Part V - Reinforcement Learning</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#part-vi---generative-models"><i class="fa fa-check"></i><b>1.6</b> Part VI - Generative Models</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#part-vii---operationalization-methods"><i class="fa fa-check"></i><b>1.7</b> Part VII - Operationalization Methods</a></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#useful-resources"><i class="fa fa-check"></i><b>1.8</b> Useful Resources</a><ul>
<li class="chapter" data-level="1.8.1" data-path="index.html"><a href="index.html#online-courses"><i class="fa fa-check"></i><b>1.8.1</b> Online Courses</a></li>
<li class="chapter" data-level="1.8.2" data-path="index.html"><a href="index.html#online-books-and-blogs"><i class="fa fa-check"></i><b>1.8.2</b> Online Books and Blogs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="provisioning-linux-dsvms-with-azure-cli-2-0.html"><a href="provisioning-linux-dsvms-with-azure-cli-2-0.html"><i class="fa fa-check"></i><b>2</b> Provisioning Linux DSVMs with Azure CLI 2.0</a><ul>
<li class="chapter" data-level="2.1" data-path="provisioning-linux-dsvms-with-azure-cli-2-0.html"><a href="provisioning-linux-dsvms-with-azure-cli-2-0.html#installing-and-testing-the-azure-cli"><i class="fa fa-check"></i><b>2.1</b> Installing and Testing the Azure CLI</a></li>
<li class="chapter" data-level="2.2" data-path="provisioning-linux-dsvms-with-azure-cli-2-0.html"><a href="provisioning-linux-dsvms-with-azure-cli-2-0.html#login-to-your-azure-account"><i class="fa fa-check"></i><b>2.2</b> Login to Your Azure Account</a></li>
<li class="chapter" data-level="2.3" data-path="provisioning-linux-dsvms-with-azure-cli-2-0.html"><a href="provisioning-linux-dsvms-with-azure-cli-2-0.html#deploying-with-a-custom-script"><i class="fa fa-check"></i><b>2.3</b> Deploying with a Custom Script</a></li>
<li class="chapter" data-level="2.4" data-path="provisioning-linux-dsvms-with-azure-cli-2-0.html"><a href="provisioning-linux-dsvms-with-azure-cli-2-0.html#updating-dsvm-os-disk-size"><i class="fa fa-check"></i><b>2.4</b> Updating DSVM OS Disk Size</a></li>
<li class="chapter" data-level="2.5" data-path="provisioning-linux-dsvms-with-azure-cli-2-0.html"><a href="provisioning-linux-dsvms-with-azure-cli-2-0.html#deploying-manually-only-proceed-if-you-didnt-use-the-script-above"><i class="fa fa-check"></i><b>2.5</b> Deploying Manually <strong>(Only Proceed if You Didn’t Use the Script Above!)</strong></a><ul>
<li class="chapter" data-level="2.5.1" data-path="provisioning-linux-dsvms-with-azure-cli-2-0.html"><a href="provisioning-linux-dsvms-with-azure-cli-2-0.html#create-a-new-resource-group"><i class="fa fa-check"></i><b>2.5.1</b> Create a New Resource Group</a></li>
<li class="chapter" data-level="2.5.2" data-path="provisioning-linux-dsvms-with-azure-cli-2-0.html"><a href="provisioning-linux-dsvms-with-azure-cli-2-0.html#create-your-dsvm"><i class="fa fa-check"></i><b>2.5.2</b> Create Your DSVM</a></li>
<li class="chapter" data-level="2.5.3" data-path="provisioning-linux-dsvms-with-azure-cli-2-0.html"><a href="provisioning-linux-dsvms-with-azure-cli-2-0.html#create-a-password-for-the-user"><i class="fa fa-check"></i><b>2.5.3</b> Create a Password for the User</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="upgrading-cntk-and-cudnn.html"><a href="upgrading-cntk-and-cudnn.html"><i class="fa fa-check"></i><b>3</b> Upgrading CNTK and CUDNN</a><ul>
<li class="chapter" data-level="3.1" data-path="upgrading-cntk-and-cudnn.html"><a href="upgrading-cntk-and-cudnn.html#updating-cntk"><i class="fa fa-check"></i><b>3.1</b> Updating CNTK</a></li>
<li class="chapter" data-level="3.2" data-path="upgrading-cntk-and-cudnn.html"><a href="upgrading-cntk-and-cudnn.html#updating-cntk-with-a-single-script"><i class="fa fa-check"></i><b>3.2</b> Updating CNTK With a Single Script</a><ul>
<li class="chapter" data-level="3.2.1" data-path="upgrading-cntk-and-cudnn.html"><a href="upgrading-cntk-and-cudnn.html#launch-jupyterlab"><i class="fa fa-check"></i><b>3.2.1</b> Launch JupyterLab</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="upgrading-cntk-and-cudnn.html"><a href="upgrading-cntk-and-cudnn.html#manually-updating-cntk-and-launching-jupyter-no-need-to-do-this-if-you-use-the-script"><i class="fa fa-check"></i><b>3.3</b> Manually Updating CNTK and Launching Jupyter (<strong>No Need to Do This if You Use the Script</strong>)</a><ul>
<li class="chapter" data-level="3.3.1" data-path="upgrading-cntk-and-cudnn.html"><a href="upgrading-cntk-and-cudnn.html#create-conda-virtual-environment"><i class="fa fa-check"></i><b>3.3.1</b> Create Conda Virtual Environment</a></li>
<li class="chapter" data-level="3.3.2" data-path="upgrading-cntk-and-cudnn.html"><a href="upgrading-cntk-and-cudnn.html#install-cntk-using-pip-binary-wheels"><i class="fa fa-check"></i><b>3.3.2</b> Install CNTK Using <code>pip</code> Binary Wheels</a></li>
<li class="chapter" data-level="3.3.3" data-path="upgrading-cntk-and-cudnn.html"><a href="upgrading-cntk-and-cudnn.html#temporary-fixes"><i class="fa fa-check"></i><b>3.3.3</b> Temporary Fixes</a></li>
<li class="chapter" data-level="3.3.4" data-path="upgrading-cntk-and-cudnn.html"><a href="upgrading-cntk-and-cudnn.html#conda-extensions"><i class="fa fa-check"></i><b>3.3.4</b> Conda Extensions</a></li>
<li class="chapter" data-level="3.3.5" data-path="upgrading-cntk-and-cudnn.html"><a href="upgrading-cntk-and-cudnn.html#install-keras"><i class="fa fa-check"></i><b>3.3.5</b> Install Keras</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="transfer-learning-with-cntk.html"><a href="transfer-learning-with-cntk.html"><i class="fa fa-check"></i><b>4</b> Transfer Learning with CNTK</a><ul>
<li class="chapter" data-level="4.1" data-path="transfer-learning-with-cntk.html"><a href="transfer-learning-with-cntk.html#classifying-dogs-and-cats-using-a-pre-trained-network"><i class="fa fa-check"></i><b>4.1</b> Classifying Dogs and Cats Using a Pre-Trained Network</a><ul>
<li class="chapter" data-level="4.1.1" data-path="transfer-learning-with-cntk.html"><a href="transfer-learning-with-cntk.html#download-data"><i class="fa fa-check"></i><b>4.1.1</b> Download Data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="transfer-learning-with-cntk.html"><a href="transfer-learning-with-cntk.html#create-train-test-and-validate-sets"><i class="fa fa-check"></i><b>4.2</b> Create Train, Test and Validate Sets</a></li>
<li class="chapter" data-level="4.3" data-path="transfer-learning-with-cntk.html"><a href="transfer-learning-with-cntk.html#kittypupsploration"><i class="fa fa-check"></i><b>4.3</b> Kittypupsploration</a></li>
<li class="chapter" data-level="4.4" data-path="transfer-learning-with-cntk.html"><a href="transfer-learning-with-cntk.html#data-readers-in-cntk"><i class="fa fa-check"></i><b>4.4</b> Data Readers in CNTK</a></li>
<li class="chapter" data-level="4.5" data-path="transfer-learning-with-cntk.html"><a href="transfer-learning-with-cntk.html#pre-trained-models"><i class="fa fa-check"></i><b>4.5</b> Pre-Trained Models</a></li>
<li class="chapter" data-level="4.6" data-path="transfer-learning-with-cntk.html"><a href="transfer-learning-with-cntk.html#defining-model-architecture"><i class="fa fa-check"></i><b>4.6</b> Defining Model Architecture</a></li>
<li class="chapter" data-level="4.7" data-path="transfer-learning-with-cntk.html"><a href="transfer-learning-with-cntk.html#training-the-transfer-model"><i class="fa fa-check"></i><b>4.7</b> Training the Transfer Model</a></li>
<li class="chapter" data-level="4.8" data-path="transfer-learning-with-cntk.html"><a href="transfer-learning-with-cntk.html#define-minibatch-source"><i class="fa fa-check"></i><b>4.8</b> Define Minibatch Source</a></li>
<li class="chapter" data-level="4.9" data-path="transfer-learning-with-cntk.html"><a href="transfer-learning-with-cntk.html#training"><i class="fa fa-check"></i><b>4.9</b> Training</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="fashion-mnist.html"><a href="fashion-mnist.html"><i class="fa fa-check"></i><b>5</b> Fashion MNIST</a><ul>
<li class="chapter" data-level="5.1" data-path="fashion-mnist.html"><a href="fashion-mnist.html#import-core-libraries-and-specify-keras-backend"><i class="fa fa-check"></i><b>5.1</b> Import Core Libraries and Specify Keras Backend</a></li>
<li class="chapter" data-level="5.2" data-path="fashion-mnist.html"><a href="fashion-mnist.html#downloading-fashion-dataset"><i class="fa fa-check"></i><b>5.2</b> Downloading Fashion Dataset</a></li>
<li class="chapter" data-level="5.3" data-path="fashion-mnist.html"><a href="fashion-mnist.html#scale-data-and-visualize"><i class="fa fa-check"></i><b>5.3</b> Scale Data and Visualize</a></li>
<li class="chapter" data-level="5.4" data-path="fashion-mnist.html"><a href="fashion-mnist.html#create-network-architecture-and-model-parameters"><i class="fa fa-check"></i><b>5.4</b> Create Network Architecture and Model Parameters</a></li>
<li class="chapter" data-level="5.5" data-path="fashion-mnist.html"><a href="fashion-mnist.html#training-our-model"><i class="fa fa-check"></i><b>5.5</b> Training Our Model</a></li>
<li class="chapter" data-level="5.6" data-path="fashion-mnist.html"><a href="fashion-mnist.html#scoring-the-model"><i class="fa fa-check"></i><b>5.6</b> Scoring the Model</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="neural-style-transfer.html"><a href="neural-style-transfer.html"><i class="fa fa-check"></i><b>6</b> Neural Style Transfer</a><ul>
<li class="chapter" data-level="6.1" data-path="neural-style-transfer.html"><a href="neural-style-transfer.html#defining-the-loss-function"><i class="fa fa-check"></i><b>6.1</b> Defining the loss function</a></li>
<li class="chapter" data-level="6.2" data-path="neural-style-transfer.html"><a href="neural-style-transfer.html#instantiating-the-loss"><i class="fa fa-check"></i><b>6.2</b> Instantiating the loss</a></li>
<li class="chapter" data-level="6.3" data-path="neural-style-transfer.html"><a href="neural-style-transfer.html#optimizing-the-loss"><i class="fa fa-check"></i><b>6.3</b> Optimizing the loss</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="network-visualization-tensorflow.html"><a href="network-visualization-tensorflow.html"><i class="fa fa-check"></i><b>7</b> Network Visualization (TensorFlow)</a></li>
<li class="chapter" data-level="8" data-path="pretrained-model.html"><a href="pretrained-model.html"><i class="fa fa-check"></i><b>8</b> Pretrained Model</a><ul>
<li class="chapter" data-level="8.1" data-path="pretrained-model.html"><a href="pretrained-model.html#load-some-imagenet-images"><i class="fa fa-check"></i><b>8.1</b> Load some ImageNet images</a></li>
<li class="chapter" data-level="8.2" data-path="pretrained-model.html"><a href="pretrained-model.html#preprocess-images"><i class="fa fa-check"></i><b>8.2</b> Preprocess images</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="saliency-maps.html"><a href="saliency-maps.html"><i class="fa fa-check"></i><b>9</b> Saliency Maps</a></li>
<li class="chapter" data-level="10" data-path="fooling-images.html"><a href="fooling-images.html"><i class="fa fa-check"></i><b>10</b> Fooling Images</a></li>
<li class="chapter" data-level="11" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><i class="fa fa-check"></i><b>11</b> Wasserstein GAN and Loss Sensitive GAN with CIFAR Data</a><ul>
<li class="chapter" data-level="11.1" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#introduction"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#overview"><i class="fa fa-check"></i><b>11.2</b> Overview</a><ul>
<li class="chapter" data-level="11.2.1" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#why-is-gan-hard-to-train"><i class="fa fa-check"></i><b>11.2.1</b> Why is GAN hard to train?</a></li>
<li class="chapter" data-level="11.2.2" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#wasserstein-gan"><i class="fa fa-check"></i><b>11.2.2</b> Wasserstein GAN</a></li>
<li class="chapter" data-level="11.2.3" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#loss-sensitive-gan"><i class="fa fa-check"></i><b>11.2.3</b> Loss Sensitive GAN</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#data-reading"><i class="fa fa-check"></i><b>11.3</b> Data Reading</a></li>
<li class="chapter" data-level="11.4" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#model-creation-w-gan"><i class="fa fa-check"></i><b>11.4</b> Model Creation (W-GAN)</a><ul>
<li class="chapter" data-level="11.4.1" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#build-the-graph"><i class="fa fa-check"></i><b>11.4.1</b> Build the graph</a></li>
<li class="chapter" data-level="11.4.2" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#train-the-model"><i class="fa fa-check"></i><b>11.4.2</b> Train the Model</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#generating-fake-synthetic-images-w-gan"><i class="fa fa-check"></i><b>11.5</b> Generating Fake (Synthetic) Images (W-GAN)</a></li>
<li class="chapter" data-level="11.6" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#model-creation-ls-gan"><i class="fa fa-check"></i><b>11.6</b> Model Creation (LS-GAN)</a><ul>
<li class="chapter" data-level="11.6.1" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#build-the-graph-1"><i class="fa fa-check"></i><b>11.6.1</b> Build the graph</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#train-the-model-1"><i class="fa fa-check"></i><b>11.7</b> Train the model</a></li>
<li class="chapter" data-level="11.8" data-path="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html"><a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html#generating-fake-synthetic-images-ls-gan"><i class="fa fa-check"></i><b>11.8</b> Generating Fake (Synthetic) Images (LS-GAN)</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html"><a href="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html"><i class="fa fa-check"></i><b>12</b> Synthesizing Faces of Celebrities Boundary Equilibrium GAN with CelebA data</a><ul>
<li class="chapter" data-level="12.1" data-path="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html"><a href="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html#introduction-1"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html"><a href="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html#download-data-1"><i class="fa fa-check"></i><b>12.2</b> Download Data</a></li>
<li class="chapter" data-level="12.3" data-path="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html"><a href="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html#read-data"><i class="fa fa-check"></i><b>12.3</b> Read Data</a></li>
<li class="chapter" data-level="12.4" data-path="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html"><a href="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html#model-creation"><i class="fa fa-check"></i><b>12.4</b> Model Creation</a><ul>
<li class="chapter" data-level="12.4.1" data-path="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html"><a href="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html#model-components"><i class="fa fa-check"></i><b>12.4.1</b> Model components</a></li>
<li class="chapter" data-level="12.4.2" data-path="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html"><a href="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html#build-the-graph-2"><i class="fa fa-check"></i><b>12.4.2</b> Build the graph</a></li>
<li class="chapter" data-level="12.4.3" data-path="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html"><a href="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html#train-the-model-2"><i class="fa fa-check"></i><b>12.4.3</b> Train the Model</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html"><a href="synthesizing-faces-of-celebrities-boundary-equilibrium-gan-with-celeba-data.html#generating-fake-synthesized-images"><i class="fa fa-check"></i><b>12.5</b> Generating Fake (Synthesized) Images</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html"><i class="fa fa-check"></i><b>13</b> How to make a racist AI without really trying</a><ul>
<li class="chapter" data-level="13.1" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#lets-make-a-sentiment-classifier"><i class="fa fa-check"></i><b>13.1</b> Let’s make a sentiment classifier!</a></li>
<li class="chapter" data-level="13.2" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#software-dependencies"><i class="fa fa-check"></i><b>13.2</b> Software dependencies</a></li>
<li class="chapter" data-level="13.3" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#step-1-word-embeddings"><i class="fa fa-check"></i><b>13.3</b> Step 1: Word embeddings</a></li>
<li class="chapter" data-level="13.4" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#step-2-a-gold-standard-sentiment-lexicon"><i class="fa fa-check"></i><b>13.4</b> Step 2: A gold-standard sentiment lexicon</a></li>
<li class="chapter" data-level="13.5" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#step-3-train-a-model-to-predict-word-sentiments"><i class="fa fa-check"></i><b>13.5</b> Step 3: Train a model to predict word sentiments</a></li>
<li class="chapter" data-level="13.6" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#step-4-get-a-sentiment-score-for-text"><i class="fa fa-check"></i><b>13.6</b> Step 4: Get a sentiment score for text</a></li>
<li class="chapter" data-level="13.7" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#step-5-behold-the-monstrosity-that-we-have-created"><i class="fa fa-check"></i><b>13.7</b> Step 5: Behold the monstrosity that we have created</a></li>
<li class="chapter" data-level="13.8" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#step-6-measure-the-problem"><i class="fa fa-check"></i><b>13.8</b> Step 6: Measure the problem</a></li>
<li class="chapter" data-level="13.9" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#step-7-trying-different-data"><i class="fa fa-check"></i><b>13.9</b> Step 7: Trying different data</a><ul>
<li class="chapter" data-level="13.9.1" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#trying-word2vec"><i class="fa fa-check"></i><b>13.9.1</b> Trying word2vec</a></li>
<li class="chapter" data-level="13.9.2" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#trying-conceptnet-numberbatch"><i class="fa fa-check"></i><b>13.9.2</b> Trying ConceptNet Numberbatch</a></li>
<li class="chapter" data-level="13.9.3" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#there-is-no-trade-off"><i class="fa fa-check"></i><b>13.9.3</b> There is no trade-off</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="how-to-make-a-racist-ai-without-really-trying.html"><a href="how-to-make-a-racist-ai-without-really-trying.html#other-approaches"><i class="fa fa-check"></i><b>13.10</b> Other approaches</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://aka.ms/az-dl" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Deep Learning on Azure</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="fooling-images" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Fooling Images</h1>
<p>We can also use image gradients to generate “fooling images” as discussed in [3]. Given an image and a target class, we can perform gradient <strong>ascent</strong> over the image to maximize the target class, stopping when the network classifies the image as the target class. Implement the following function to generate fooling images.</p>
<p>[3] [Szegedy et al, “Intriguing properties of neural networks”, ICLR 2014](<a href="https://arxiv.org/abs/1312.6199" class="uri">https://arxiv.org/abs/1312.6199</a>)</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> make_fooling_image(X, target_y, model):
    <span class="co">&quot;&quot;&quot;</span>
<span class="co">    Generate a fooling image that is close to X, but that the model classifies</span>
<span class="co">    as target_y.</span>

<span class="co">    Inputs:</span>
<span class="co">    - X: Input image, of shape (1, 224, 224, 3)</span>
<span class="co">    - target_y: An integer in the range [0, 1000)</span>
<span class="co">    - model: Pretrained SqueezeNet model</span>

<span class="co">    Returns:</span>
<span class="co">    - X_fooling: An image that is close to X, but that is classifed as target_y</span>
<span class="co">    by the model.</span>
<span class="co">    &quot;&quot;&quot;</span>
    X_fooling <span class="op">=</span> X.copy()
    learning_rate <span class="op">=</span> <span class="dv">1</span>
    <span class="co">##############################################################################</span>
    <span class="co"># </span><span class="al">TODO</span><span class="co">: Generate a fooling image X_fooling that the model will classify as   #</span>
    <span class="co"># the class target_y. Use gradient ascent on the target class score, using   #</span>
    <span class="co"># the model.classifier Tensor to get the class scores for the model.image.   #</span>
    <span class="co"># When computing an update step, first normalize the gradient:               #</span>
    <span class="co">#   dX = learning_rate * g / ||g||_2                                         #</span>
    <span class="co">#                                                                            #</span>
    <span class="co"># You should write a training loop                                           #</span>
    <span class="co">#                                                                            #  </span>
    <span class="co"># HINT: For most examples, you should be able to generate a fooling image    #</span>
    <span class="co"># in fewer than 100 iterations of gradient ascent.                           #</span>
    <span class="co"># You can print your progress over iterations to check your algorithm.       #</span>
    <span class="co">##############################################################################</span>
    iterations <span class="op">=</span> <span class="dv">100</span>
    loss <span class="op">=</span> model.classifier[<span class="dv">0</span>][target_y]
    grad <span class="op">=</span> tf.gradients(loss, model.image)[<span class="dv">0</span>]
    
    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iterations):
        scores <span class="op">=</span> sess.run(model.classifier, feed_dict<span class="op">=</span>{model.image: X_fooling})
        g <span class="op">=</span> sess.run(grad, feed_dict<span class="op">=</span>{model.image: X_fooling})
        target_i <span class="op">=</span> np.argmax(scores[<span class="dv">0</span>])
        <span class="cf">if</span> target_i <span class="op">==</span> target_y:
            <span class="cf">break</span><span class="op">;</span>
        <span class="cf">else</span>:
            dX <span class="op">=</span> learning_rate <span class="op">*</span> g <span class="op">/</span> np.sqrt(np.<span class="bu">sum</span>(g<span class="op">*</span>g))
            X_fooling <span class="op">+=</span> dX
    <span class="co">##############################################################################</span>
    <span class="co">#                             </span><span class="re">END</span><span class="co"> OF YOUR CODE                               #</span>
    <span class="co">##############################################################################</span>
    <span class="cf">return</span> X_fooling</code></pre></div>
<p>Run the following to generate a fooling image. Feel free to change the <code>idx</code> variable to explore other images.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">idx <span class="op">=</span> <span class="dv">2</span>
Xi <span class="op">=</span> X[idx][<span class="va">None</span>]
target_y <span class="op">=</span> <span class="dv">9</span>
X_fooling <span class="op">=</span> make_fooling_image(Xi, target_y, model)

<span class="co"># Make sure that X_fooling is classified as y_target</span>
scores <span class="op">=</span> sess.run(model.classifier, {model.image: X_fooling})
<span class="cf">assert</span> scores[<span class="dv">0</span>].argmax() <span class="op">==</span> target_y, <span class="st">&#39;The network is not fooled!&#39;</span>

<span class="co"># Show original image, fooling image, and difference</span>
orig_img <span class="op">=</span> deprocess_image(Xi[<span class="dv">0</span>])
fool_img <span class="op">=</span> deprocess_image(X_fooling[<span class="dv">0</span>])
<span class="co"># Rescale </span>
plt.subplot(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">1</span>)
plt.imshow(orig_img)
plt.axis(<span class="st">&#39;off&#39;</span>)
plt.title(class_names[y[idx]])
plt.subplot(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">2</span>)
plt.imshow(fool_img)
plt.title(class_names[target_y])
plt.axis(<span class="st">&#39;off&#39;</span>)
plt.subplot(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">3</span>)
plt.title(<span class="st">&#39;Difference&#39;</span>)
plt.imshow(deprocess_image((Xi<span class="op">-</span>X_fooling)[<span class="dv">0</span>]))
plt.axis(<span class="st">&#39;off&#39;</span>)
plt.subplot(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">4</span>)
plt.title(<span class="st">&#39;Magnified difference (10x)&#39;</span>)
plt.imshow(deprocess_image(<span class="dv">10</span> <span class="op">*</span> (Xi<span class="op">-</span>X_fooling)[<span class="dv">0</span>]))
plt.axis(<span class="st">&#39;off&#39;</span>)
plt.gcf().tight_layout()</code></pre></div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_17_0.png" alt="png" />
<p class="caption">png</p>
</div>
<div id="class-visualization" class="section level5">
<h5><span class="header-section-number">10.0.0.0.1</span> Class visualization</h5>
<p>By starting with a random noise image and performing gradient ascent on a target class, we can generate an image that the network will recognize as the target class. This idea was first presented in [2]; [3] extended this idea by suggesting several regularization techniques that can improve the quality of the generated image.</p>
<p>Concretely, let <span class="math inline">\(I\)</span> be an image and let <span class="math inline">\(y\)</span> be a target class. Let <span class="math inline">\(s_y(I)\)</span> be the score that a convolutional network assigns to the image <span class="math inline">\(I\)</span> for class <span class="math inline">\(y\)</span>; note that these are raw unnormalized scores, not class probabilities. We wish to generate an image <span class="math inline">\(I^*\)</span> that achieves a high score for the class <span class="math inline">\(y\)</span> by solving the problem</p>
<p><span class="math display">\[
I^* = \arg\max_I s_y(I) - R(I)
\]</span></p>
<p>where <span class="math inline">\(R\)</span> is a (possibly implicit) regularizer (note the sign of <span class="math inline">\(R(I)\)</span> in the argmax: we want to minimize this regularization term). We can solve this optimization problem using gradient ascent, computing gradients with respect to the generated image. We will use (explicit) L2 regularization of the form</p>
<p><span class="math display">\[
R(I) = \lambda \|I\|_2^2
\]</span></p>
<p><strong>and</strong> implicit regularization as suggested by [3] by periodically blurring the generated image. We can solve this problem using gradient ascent on the generated image.</p>
<p>In the cell below, complete the implementation of the <code>create_class_visualization</code> function.</p>
<p>[2] [Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. “Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps”, ICLR Workshop 2014](<a href="https://arxiv.org/abs/1312.6034" class="uri">https://arxiv.org/abs/1312.6034</a>).</p>
<p>[3] [Yosinski et al, “Understanding Neural Networks Through Deep Visualization”, ICML 2015 Deep Learning Workshop](<a href="https://arxiv.org/abs/1506.06579" class="uri">https://arxiv.org/abs/1506.06579</a>).</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> scipy.ndimage.filters <span class="im">import</span> gaussian_filter1d
<span class="kw">def</span> blur_image(X, sigma<span class="op">=</span><span class="dv">1</span>):
    X <span class="op">=</span> gaussian_filter1d(X, sigma, axis<span class="op">=</span><span class="dv">1</span>)
    X <span class="op">=</span> gaussian_filter1d(X, sigma, axis<span class="op">=</span><span class="dv">2</span>)
    <span class="cf">return</span> X</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> create_class_visualization(target_y, model, <span class="op">**</span>kwargs):
    <span class="co">&quot;&quot;&quot;</span>
<span class="co">    Generate an image to maximize the score of target_y under a pretrained model.</span>
<span class="co">    </span>
<span class="co">    Inputs:</span>
<span class="co">    - target_y: Integer in the range [0, 1000) giving the index of the class</span>
<span class="co">    - model: A pretrained CNN that will be used to generate the image</span>
<span class="co">    </span>
<span class="co">    Keyword arguments:</span>
<span class="co">    - l2_reg: Strength of L2 regularization on the image</span>
<span class="co">    - learning_rate: How big of a step to take</span>
<span class="co">    - num_iterations: How many iterations to use</span>
<span class="co">    - blur_every: How often to blur the image as an implicit regularizer</span>
<span class="co">    - max_jitter: How much to gjitter the image as an implicit regularizer</span>
<span class="co">    - show_every: How often to show the intermediate result</span>
<span class="co">    &quot;&quot;&quot;</span>
    l2_reg <span class="op">=</span> kwargs.pop(<span class="st">&#39;l2_reg&#39;</span>, <span class="fl">1e-3</span>)
    learning_rate <span class="op">=</span> kwargs.pop(<span class="st">&#39;learning_rate&#39;</span>, <span class="dv">25</span>)
    num_iterations <span class="op">=</span> kwargs.pop(<span class="st">&#39;num_iterations&#39;</span>, <span class="dv">1000</span>)
    blur_every <span class="op">=</span> kwargs.pop(<span class="st">&#39;blur_every&#39;</span>, <span class="dv">10</span>)
    max_jitter <span class="op">=</span> kwargs.pop(<span class="st">&#39;max_jitter&#39;</span>, <span class="dv">1</span>)
    show_every <span class="op">=</span> kwargs.pop(<span class="st">&#39;show_every&#39;</span>, <span class="dv">25</span>)

    X <span class="op">=</span> <span class="dv">255</span> <span class="op">*</span> np.random.rand(<span class="dv">224</span>, <span class="dv">224</span>, <span class="dv">3</span>)
    X <span class="op">=</span> preprocess_image(X)[<span class="va">None</span>]
    
    <span class="co">########################################################################</span>
    <span class="co"># </span><span class="al">TODO</span><span class="co">: Compute the loss and the gradient of the loss with respect to  #</span>
    <span class="co"># the input image, model.image. We compute these outside the loop so   #</span>
    <span class="co"># that we don&#39;t have to recompute the gradient graph at each iteration #</span>
    <span class="co">#                                                                      #</span>
    <span class="co"># Note: loss and grad should be TensorFlow Tensors, not numpy arrays!  #</span>
    <span class="co">#                                                                      #</span>
    <span class="co"># The loss is the score for the target label, target_y. You should     #</span>
    <span class="co"># use model.classifier to get the scores, and tf.gradients to compute  #</span>
    <span class="co"># gradients. Don&#39;t forget the (subtracted) L2 regularization term!     #</span>
    <span class="co">########################################################################</span>
    loss <span class="op">=</span> <span class="va">None</span> <span class="co"># scalar loss</span>
    grad <span class="op">=</span> <span class="va">None</span> <span class="co"># gradient of loss with respect to model.image, same size as model.image</span>
    penalty <span class="op">=</span> l2_reg <span class="op">*</span> tf.norm(model.image)
    loss <span class="op">=</span> model.classifier[<span class="dv">0</span>, target_y] <span class="op">-</span> penalty
    grad <span class="op">=</span> tf.gradients(loss, model.image)[<span class="dv">0</span>]
    <span class="co">############################################################################</span>
    <span class="co">#                             </span><span class="re">END</span><span class="co"> OF YOUR CODE                             #</span>
    <span class="co">############################################################################</span>

    
    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(num_iterations):
        <span class="co"># Randomly jitter the image a bit; this gives slightly nicer results</span>
        ox, oy <span class="op">=</span> np.random.randint(<span class="op">-</span>max_jitter, max_jitter<span class="op">+</span><span class="dv">1</span>, <span class="dv">2</span>)
        Xi <span class="op">=</span> X.copy()
        X <span class="op">=</span> np.roll(np.roll(X, ox, <span class="dv">1</span>), oy, <span class="dv">2</span>)
        
        <span class="co">########################################################################</span>
        <span class="co"># </span><span class="al">TODO</span><span class="co">: Use sess to compute the value of the gradient of the score for #</span>
        <span class="co"># class target_y with respect to the pixels of the image, and make a   #</span>
        <span class="co"># gradient step on the image using the learning rate. You should use   #</span>
        <span class="co"># the grad variable you defined above.                                 #</span>
        <span class="co">#                                                                      #</span>
        <span class="co"># Be very careful about the signs of elements in your code.            #</span>
        <span class="co">########################################################################</span>
        grad_val <span class="op">=</span> sess.run(grad, {model.image: X})
        dX <span class="op">=</span> learning_rate <span class="op">*</span> grad_val<span class="op">/</span>np.linalg.norm(grad_val)
        X <span class="op">+=</span> dX
        <span class="co">############################################################################</span>
        <span class="co">#                             </span><span class="re">END</span><span class="co"> OF YOUR CODE                             #</span>
        <span class="co">############################################################################</span>

        <span class="co"># Undo the jitter</span>
        X <span class="op">=</span> np.roll(np.roll(X, <span class="op">-</span>ox, <span class="dv">1</span>), <span class="op">-</span>oy, <span class="dv">2</span>)

        <span class="co"># As a regularizer, clip and periodically blur</span>
        X <span class="op">=</span> np.clip(X, <span class="op">-</span>SQUEEZENET_MEAN<span class="op">/</span>SQUEEZENET_STD, (<span class="fl">1.0</span> <span class="op">-</span> SQUEEZENET_MEAN)<span class="op">/</span>SQUEEZENET_STD)
        <span class="cf">if</span> t <span class="op">%</span> blur_every <span class="op">==</span> <span class="dv">0</span>:
            X <span class="op">=</span> blur_image(X, sigma<span class="op">=</span><span class="fl">0.5</span>)

        <span class="co"># Periodically show the image</span>
        <span class="cf">if</span> t <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> (t <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> show_every <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> t <span class="op">==</span> num_iterations <span class="op">-</span> <span class="dv">1</span>:
            plt.imshow(deprocess_image(X[<span class="dv">0</span>]))
            class_name <span class="op">=</span> class_names[target_y]
            plt.title(<span class="st">&#39;</span><span class="sc">%s</span><span class="ch">\n</span><span class="st">Iteration </span><span class="sc">%d</span><span class="st"> / </span><span class="sc">%d</span><span class="st">&#39;</span> <span class="op">%</span> (class_name, t <span class="op">+</span> <span class="dv">1</span>, num_iterations))
            plt.gcf().set_size_inches(<span class="dv">4</span>, <span class="dv">4</span>)
            plt.axis(<span class="st">&#39;off&#39;</span>)
            plt.show()
    <span class="cf">return</span> X</code></pre></div>
<p>Once you have completed the implementation in the cell above, run the following cell to generate an image of Tarantula:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">target_y <span class="op">=</span> <span class="dv">7</span> <span class="co"># Tarantula</span>
out <span class="op">=</span> create_class_visualization(target_y, model)</code></pre></div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_0.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_1.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_2.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_3.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_4.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_5.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_6.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_7.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_8.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_9.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_10.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_11.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_12.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_13.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_14.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_15.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_16.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_17.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_18.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_19.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_20.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_21.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_22.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_23.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_24.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_25.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_26.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_27.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_28.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_29.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_30.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_31.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_32.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_33.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_34.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_35.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_36.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_37.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_38.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_39.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_22_40.png" alt="png" />
<p class="caption">png</p>
</div>
<p>Try out your class visualization on other classes! You should also feel free to play with various hyperparameters to try and improve the quality of the generated image, but this is not required.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># target_y = 78 # Tick</span>
target_y <span class="op">=</span> <span class="dv">187</span> <span class="co"># Yorkshire Terrier</span>
<span class="co"># target_y = 683 # Oboe</span>
<span class="co"># target_y = 366 # Gorilla</span>
<span class="co"># target_y = 604 # Hourglass</span>
<span class="co"># target_y = np.random.randint(1000)</span>
<span class="bu">print</span>(class_names[target_y])
X <span class="op">=</span> create_class_visualization(target_y, model)</code></pre></div>
<pre><code>Yorkshire terrier</code></pre>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_1.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_2.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_3.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_4.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_5.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_6.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_7.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_8.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_9.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_10.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_11.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_12.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_13.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_14.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_15.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_16.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_17.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_18.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_19.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_20.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_21.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_22.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_23.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_24.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_25.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_26.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_27.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_28.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_29.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_30.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_31.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_32.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_33.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_34.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_35.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_36.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_37.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_38.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_39.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_40.png" alt="png" />
<p class="caption">png</p>
</div>
<div class="figure">
<img src="Network-Visualization-TensorFlow_files/Network-Visualization-TensorFlow_24_41.png" alt="png" />
<p class="caption">png</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="saliency-maps.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="wasserstein-gan-and-loss-sensitive-gan-with-cifar-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/Azure/learnAnalytics-DeepLearning-Azure/edit/master/06-Adversarial-Attacks.Rmd",
"text": "Edit"
},
"download": ["azure-deep-learning.pdf", "azure-deep-learning.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
